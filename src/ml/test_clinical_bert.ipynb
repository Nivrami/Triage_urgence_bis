{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üß™ Test ClinicalBERT / CamemBERT-bio\n",
    "\n",
    "Ce notebook teste les mod√®les de text encoding m√©dical.\n",
    "\n",
    "**Mod√®les disponibles :**\n",
    "- `ClinicalBERT` : Anglais (medicalai/ClinicalBERT)\n",
    "- `CamemBERT-bio` : Fran√ßais (almanach/camembert-bio-base) ‚≠ê RECOMMAND√â"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Installation des d√©pendances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installer si n√©cessaire\n",
    "!pip install transformers torch -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\Desktop\\Master2\\llm\\Triage_urgence\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ PyTorch version: 2.10.0+cpu\n",
      "‚úÖ CUDA disponible: False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import numpy as np\n",
    "\n",
    "print(f\"‚úÖ PyTorch version: {torch.__version__}\")\n",
    "print(f\"‚úÖ CUDA disponible: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Test CamemBERT-bio (Fran√ßais) ‚≠ê"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Chargement CamemBERT-bio...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\Desktop\\Master2\\llm\\Triage_urgence\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:130: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\HP\\.cache\\huggingface\\hub\\models--almanach--camembert-bio-base. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Loading weights: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 197/197 [00:00<00:00, 826.58it/s, Materializing param=encoder.layer.11.output.dense.weight]              \n",
      "CamembertModel LOAD REPORT from: almanach/camembert-bio-base\n",
      "Key                             | Status     | \n",
      "--------------------------------+------------+-\n",
      "lm_head.bias                    | UNEXPECTED | \n",
      "lm_head.dense.bias              | UNEXPECTED | \n",
      "roberta.embeddings.position_ids | UNEXPECTED | \n",
      "lm_head.layer_norm.bias         | UNEXPECTED | \n",
      "lm_head.dense.weight            | UNEXPECTED | \n",
      "lm_head.layer_norm.weight       | UNEXPECTED | \n",
      "pooler.dense.weight             | MISSING    | \n",
      "pooler.dense.bias               | MISSING    | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
      "- MISSING\t:those params were newly initialized because missing from the checkpoint. Consider training on your downstream task.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Mod√®le charg√© !\n"
     ]
    }
   ],
   "source": [
    "# Charger le mod√®le fran√ßais\n",
    "print(\"üîß Chargement CamemBERT-bio...\")\n",
    "\n",
    "model_name = \"almanach/camembert-bio-base\"\n",
    "tokenizer_fr = AutoTokenizer.from_pretrained(model_name)\n",
    "model_fr = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "# Mettre en mode √©valuation\n",
    "model_fr.eval()\n",
    "\n",
    "print(\"‚úÖ Mod√®le charg√© !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Texte d'entr√©e : douleur thoracique intense, essoufflement au repos, sueurs froides\n",
      "\n",
      "üî¢ Tokens : torch.Size([1, 16])\n",
      "\n",
      "‚úÖ Embeddings extraits !\n",
      "   Shape : (1, 768)\n",
      "   Type : float32\n",
      "   Min : -1.855\n",
      "   Max : 0.524\n",
      "   Mean : 0.011\n",
      "\n",
      "   Premiers 10 valeurs : [ 0.07329346  0.19525796  0.07638985 -0.02134542 -0.12308737  0.1294392\n",
      "  0.02200944  0.14559159  0.11541703 -0.00263739]\n"
     ]
    }
   ],
   "source": [
    "# Tester avec des sympt√¥mes en fran√ßais\n",
    "symptoms_fr = [\n",
    "    \"douleur thoracique intense\",\n",
    "    \"essoufflement au repos\",\n",
    "    \"sueurs froides\"\n",
    "]\n",
    "\n",
    "# Joindre en un texte\n",
    "text_fr = \", \".join(symptoms_fr)\n",
    "print(f\"üìù Texte d'entr√©e : {text_fr}\")\n",
    "\n",
    "# Tokenize\n",
    "inputs = tokenizer_fr(text_fr, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "print(f\"\\nüî¢ Tokens : {inputs['input_ids'].shape}\")\n",
    "\n",
    "# Encoder\n",
    "with torch.no_grad():\n",
    "    outputs = model_fr(**inputs)\n",
    "\n",
    "# Extraire embeddings (token [CLS])\n",
    "embeddings = outputs.last_hidden_state[:, 0, :].numpy()\n",
    "\n",
    "print(f\"\\n‚úÖ Embeddings extraits !\")\n",
    "print(f\"   Shape : {embeddings.shape}\")\n",
    "print(f\"   Type : {embeddings.dtype}\")\n",
    "print(f\"   Min : {embeddings.min():.3f}\")\n",
    "print(f\"   Max : {embeddings.max():.3f}\")\n",
    "print(f\"   Mean : {embeddings.mean():.3f}\")\n",
    "print(f\"\\n   Premiers 10 valeurs : {embeddings[0][:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ Cr√©er une fonction r√©utilisable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_symptoms(symptoms: list, model_type=\"camembert-bio\"):\n",
    "    \"\"\"\n",
    "    Encode une liste de sympt√¥mes en embeddings.\n",
    "    \n",
    "    Args:\n",
    "        symptoms: Liste de sympt√¥mes\n",
    "        model_type: \"camembert-bio\" ou \"clinical-bert\"\n",
    "    \n",
    "    Returns:\n",
    "        np.ndarray: Embeddings (768,)\n",
    "    \"\"\"\n",
    "    # Joindre sympt√¥mes\n",
    "    text = \", \".join(symptoms)\n",
    "    \n",
    "    # Choisir mod√®le\n",
    "    if model_type == \"camembert-bio\":\n",
    "        tokenizer = tokenizer_fr\n",
    "        model = model_fr\n",
    "    else:\n",
    "        tokenizer = tokenizer_en\n",
    "        model = model_en\n",
    "    \n",
    "    # Encoder\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    embeddings = outputs.last_hidden_state[:, 0, :].numpy()\n",
    "    \n",
    "    return embeddings[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Fonction test√©e !\n",
      "   Input : ['fi√®vre √©lev√©e', 'toux s√®che', 'fatigue']\n",
      "   Output shape : (768,)\n",
      "   Exemple : [ 0.05768203  0.19409488  0.11901671 -0.06593066 -0.05924556]\n"
     ]
    }
   ],
   "source": [
    "# Test de la fonction\n",
    "test_symptoms = [\"fi√®vre √©lev√©e\", \"toux s√®che\", \"fatigue\"]\n",
    "\n",
    "emb = encode_symptoms(test_symptoms)\n",
    "\n",
    "print(f\"‚úÖ Fonction test√©e !\")\n",
    "print(f\"   Input : {test_symptoms}\")\n",
    "print(f\"   Output shape : {emb.shape}\")\n",
    "print(f\"   Exemple : {emb[:5]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
